# Configuration file for MLLM Safety Evaluation Pipeline

# Model paths (local storage)
models:
  image_generator:
    type: "qwen-image"  # "qwen-image" or "kimchi"
    # Qwen-Image settings (when type: "qwen-image")
    name: "Qwen/Qwen-Image"
    local_path: "./models_cache/qwen-image"
    torch_dtype: "bfloat16"  # bfloat16 or float16
    use_memory_efficient: true  # false = faster (GPU), true = slower but uses less VRAM (CPU offload)
    # Kimchi settings (when type: "kimchi")
    pretrained_model_path: "./models_cache/stable-diffusion-v1-5"  # Stable Diffusion v1.5 local path (required)
    clip_model_path: "./models_cache/clip-vit-large-patch14-ko"  # Korean CLIP model local path (required)
    lora_path: "./models_cache/kimchi-lora/pytorch_lora_weights.safetensors"  # LoRA weights path (required)
  
  evaluator:
    # Qwen2.5-VL models: Qwen/Qwen2.5-VL-3B-Instruct, Qwen/Qwen2.5-VL-7B-Instruct, Qwen/Qwen2.5-VL-72B-Instruct
    name: "Qwen/Qwen2.5-VL-7B-Instruct"  # Options: Qwen/Qwen2.5-VL-3B-Instruct, Qwen/Qwen2.5-VL-7B-Instruct, Qwen/Qwen2.5-VL-72B-Instruct
    local_path: "./models_cache/qwen2.5-vl-7b-instruct"
    torch_dtype: "bfloat16"
    device_map: "auto"

# Dataset settings
dataset:
  name: "naver-ai/kobbq"
  split: "test"
  local_cache_dir: "./data_cache"

# Image generation settings
image_generation:
  output_dir: "./outputs/qwen_images"
  # shared_image_path: "./outputs/hate_images/share_image.jpg"  # Use this image for all samples
  max_contexts: 10000
  num_inference_steps: 28
  true_cfg_scale: 4.0
  width: 512
  height: 512
  aspect_ratio: "1:1"  # 1:1, 16:9, 9:16, 4:3, 3:4, 3:2, 2:3

# Evaluation settings
evaluation:
  output_dir: "./outputs/evaluation_results"
  max_new_tokens: 128
  temperature: 0.0  # Greedy decoding for reproducibility
  batch_size: 1
  save_interval: 10
  prompts_file: "./evaluation/kobbq_prompts.tsv"
  prompt_ids: [1]

# Device settings
device:
  cuda_device: "cuda:0"
  use_cuda: true

# Output paths
outputs:
  image_context_mapping: "./outputs/evaluation_results/qwen-image/image_context_mapping.json"
  comparison_results: "./outputs/evaluation_results/qwen-image/qwenvl_comparison_results_prompt_{prompt_id}.json"
  evaluation_summary: "./outputs/evaluation_results/qwen-image/kobbq_comparison_evaluation_prompt_{prompt_id}.json"
  text_correct_multimodal_wrong: "./outputs/evaluation_results/qwen-image/text_correct_multimodal_wrong_prompt_{prompt_id}.json"

