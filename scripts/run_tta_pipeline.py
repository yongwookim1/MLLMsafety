#!/usr/bin/env python3
"""
TTA ë°ì´í„°ì…‹ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
1. í…ìŠ¤íŠ¸ ìƒ˜í”Œì„ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ì—¬ ì¦ê°•
2. ë©€í‹°ëª¨ë‹¬ ìƒ˜í”Œì„ ê·¸ëŒ€ë¡œ ìœ ì§€
3. ì¦ê°•ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ í‰ê°€ ì‹¤í–‰
"""

import os
import sys
import argparse
import json
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def check_requirements():
    """í•„ìˆ˜ íŒŒì¼ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸"""
    required_files = [
        "data_cache/TTA01_AssurAI/data-00000-of-00001.arrow",
        "models_cache/qwen-image",
        "models_cache/qwen2.5-vl-7b-instruct"
    ]

    missing_files = []
    for file_path in required_files:
        if not os.path.exists(file_path):
            missing_files.append(file_path)

    if missing_files:
        print("âŒ ë‹¤ìŒ íŒŒì¼ë“¤ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤:")
        for file_path in missing_files:
            print(f"  - {file_path}")
        print("\në¨¼ì € ë‹¤ìŒ ëª…ë ¹ì–´ë“¤ì„ ì‹¤í–‰í•˜ì„¸ìš”:")
        print("1. python scripts/manual_download_tta.py  # TTA ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ")
        print("2. python scripts/download_models.py       # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ")
        return False

    print("âœ… ëª¨ë“  í•„ìˆ˜ íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.")
    return True

def run_data_preparation():
    """1ë‹¨ê³„: í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
    print("\n" + "="*50)
    print("ğŸ“ 1ë‹¨ê³„: í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜")
    print("="*50)

    from scripts.prepare_tta_data import process_tta_dataset

    try:
        process_tta_dataset()
        print("âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
        return True
    except Exception as e:
        print(f"âŒ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}")
        return False

def run_evaluation(limit=None):
    """2ë‹¨ê³„: í‰ê°€ ì‹¤í–‰"""
    print("\n" + "="*50)
    print("ğŸ” 2ë‹¨ê³„: ë©€í‹°ëª¨ë‹¬ ì•ˆì „ì„± í‰ê°€")
    print("="*50)

    from scripts.run_tta_evaluation import main as run_eval

    # ì»¤ë§¨ë“œ ë¼ì¸ ì¸ì ì„¤ì •
    if limit:
        sys.argv = ['run_tta_evaluation.py', '--limit', str(limit)]
    else:
        sys.argv = ['run_tta_evaluation.py']

    try:
        run_eval()
        print("âœ… í‰ê°€ ì™„ë£Œ")
        return True
    except Exception as e:
        print(f"âŒ í‰ê°€ ì‹¤íŒ¨: {e}")
        return False

def generate_summary():
    """ê²°ê³¼ ìš”ì•½ ìƒì„±"""
    print("\n" + "="*50)
    print("ğŸ“Š ê²°ê³¼ ìš”ì•½")
    print("="*50)

    results_file = "outputs/tta_results/evaluation_results.json"
    mapping_file = "outputs/tta_image_mapping.json"

    if os.path.exists(results_file):
        with open(results_file, 'r', encoding='utf-8') as f:
            results = json.load(f)

        print(f"ğŸ“ˆ í‰ê°€ëœ ìƒ˜í”Œ ìˆ˜: {len(results)}")

        # ìœ„í—˜ ì ìˆ˜ë³„ í†µê³„
        scores = []
        for result in results:
            score = result.get('judge_result', {}).get('parsed_score')
            if score is not None:
                scores.append(score)

        if scores:
            avg_score = sum(scores) / len(scores)
            print(".2f"
            # ì ìˆ˜ ë¶„í¬
            score_counts = {}
            for score in scores:
                score_counts[score] = score_counts.get(score, 0) + 1

            print("ğŸ“Š ì ìˆ˜ ë¶„í¬:")
            for score in sorted(score_counts.keys()):
                count = score_counts[score]
                percentage = (count / len(scores)) * 100
                print(".1f"
        else:
            print("âš ï¸  íŒŒì‹±ëœ ì ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")

    if os.path.exists(mapping_file):
        with open(mapping_file, 'r', encoding='utf-8') as f:
            mapping = json.load(f)

        print(f"ğŸ–¼ï¸  ìƒì„±ëœ ì´ë¯¸ì§€ ìˆ˜: {len(mapping)}")

    print(f"\nğŸ“ ê²°ê³¼ íŒŒì¼ ìœ„ì¹˜:")
    print(f"  - í‰ê°€ ê²°ê³¼: {results_file}")
    print(f"  - ì´ë¯¸ì§€ ë§¤í•‘: {mapping_file}")
    print(f"  - ìƒì„±ëœ ì´ë¯¸ì§€: outputs/tta_images/")

def main():
    parser = argparse.ArgumentParser(description="TTA ë°ì´í„°ì…‹ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰")
    parser.add_argument("--skip-preparation", action="store_true",
                       help="ë°ì´í„° ì¤€ë¹„ ë‹¨ê³„ ê±´ë„ˆë›°ê¸°")
    parser.add_argument("--skip-evaluation", action="store_true",
                       help="í‰ê°€ ë‹¨ê³„ ê±´ë„ˆë›°ê¸°")
    parser.add_argument("--limit", type=int,
                       help="í‰ê°€í•  ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)")
    parser.add_argument("--check-only", action="store_true",
                       help="ìš”êµ¬ì‚¬í•­ë§Œ í™•ì¸í•˜ê³  ì‹¤í–‰í•˜ì§€ ì•ŠìŒ")

    args = parser.parse_args()

    print("ğŸš€ TTA ë°ì´í„°ì…‹ ë©€í‹°ëª¨ë‹¬ ì¦ê°• ë° í‰ê°€ íŒŒì´í”„ë¼ì¸")
    print("="*60)

    # ìš”êµ¬ì‚¬í•­ í™•ì¸
    if not check_requirements():
        return 1

    if args.check_only:
        print("âœ… ëª¨ë“  í™•ì¸ ì™„ë£Œ. íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return 0

    success = True

    # 1ë‹¨ê³„: ë°ì´í„° ì¤€ë¹„
    if not args.skip_preparation:
        if not run_data_preparation():
            success = False
    else:
        print("â­ï¸  ë°ì´í„° ì¤€ë¹„ ë‹¨ê³„ ê±´ë„ˆëœ€")

    # 2ë‹¨ê³„: í‰ê°€
    if not args.skip_evaluation and success:
        if not run_evaluation(args.limit):
            success = False
    else:
        print("â­ï¸  í‰ê°€ ë‹¨ê³„ ê±´ë„ˆëœ€")

    # ê²°ê³¼ ìš”ì•½
    if success:
        generate_summary()
        print("\nğŸ‰ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!")
    else:
        print("\nâŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨")

    return 0 if success else 1

if __name__ == "__main__":
    exit(main())
